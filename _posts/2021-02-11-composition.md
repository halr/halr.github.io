---
title: "Composition Sketch"
date: 2021-02-11
tags: mixd
---
My first foray into Ableton Live and Max for Live! My primary design concerns were *model* & *task*. In other words, can I learn to use Ableton Live and Max for Live with external sensors/inputs to create an interactive generative piece?

![](/images/compSketch1.png)

I am very new to Ableton Live and Max for Live. My original intention was to use an a proximity sensor as a MIDI controller. Little Bits has a [proximity sensor](https://classroom.littlebits.com/bit-o-pedia/proximity-sensor) and a [MIDI module](https://classroom.littlebits.com/bit-o-pedia/midi) that acts a voltage to MIDI converter. It worked fine has a direct controller, as did keyboard bit. Unfortunately, having never used Max for Live before, I quickly got nowhere using the set up with Max for Live.

![](/images/littlebits.png)

Having taken notes during the class Max for Live demo, I decided to reproduce the class demo as best I could. I figured a working Max MIDI Effect would be better starting place.

![](/images/maxMidiEffect.png)

Success! I was able to toggle randomly generated notes. Next, I need to try get my proximity sensor MIDI controller working through Max for Live. Also, I could not make a screen capture video with internal audio on my MacBook Air. :(
